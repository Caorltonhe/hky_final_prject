{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07945f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models, Model, Sequential\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1293d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoogLeNet(im_height=224, im_width=224, class_num=1000, aux_logits=False):\n",
    "    # tensorflow中的tensor通道排序是NHWC\n",
    "    input_image = layers.Input(shape=(im_height, im_width, 3), dtype=\"float32\")\n",
    "    # (None, 224, 224, 3)\n",
    "    x = layers.Conv2D(64, kernel_size=7, strides=2, padding=\"SAME\", activation=\"relu\", name=\"conv2d_1\")(input_image)\n",
    "    # (None, 112, 112, 64)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_1\")(x)\n",
    "    # (None, 56, 56, 64)\n",
    "    x = layers.Conv2D(64, kernel_size=1, activation=\"relu\", name=\"conv2d_2\")(x)\n",
    "    # (None, 56, 56, 64)\n",
    "    x = layers.Conv2D(192, kernel_size=3, padding=\"SAME\", activation=\"relu\", name=\"conv2d_3\")(x)\n",
    "    # (None, 56, 56, 192)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_2\")(x)\n",
    "\n",
    "    # (None, 28, 28, 192)\n",
    "    x = Inception(64, 96, 128, 16, 32, 32, name=\"inception_3a\")(x)\n",
    "    # (None, 28, 28, 256)\n",
    "    x = Inception(128, 128, 192, 32, 96, 64, name=\"inception_3b\")(x)\n",
    "\n",
    "    # (None, 28, 28, 480)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_3\")(x)\n",
    "    # (None, 14, 14, 480)\n",
    "    x = Inception(192, 96, 208, 16, 48, 64, name=\"inception_4a\")(x)\n",
    "    if aux_logits:\n",
    "        aux1 = InceptionAux(class_num, name=\"aux_1\")(x)\n",
    "\n",
    "    # (None, 14, 14, 512)\n",
    "    x = Inception(160, 112, 224, 24, 64, 64, name=\"inception_4b\")(x)\n",
    "    # (None, 14, 14, 512)\n",
    "    x = Inception(128, 128, 256, 24, 64, 64, name=\"inception_4c\")(x)\n",
    "    # (None, 14, 14, 512)\n",
    "    x = Inception(112, 144, 288, 32, 64, 64, name=\"inception_4d\")(x)\n",
    "    if aux_logits:\n",
    "        aux2 = InceptionAux(class_num, name=\"aux_2\")(x)\n",
    "\n",
    "    # (None, 14, 14, 528)\n",
    "    x = Inception(256, 160, 320, 32, 128, 128, name=\"inception_4e\")(x)\n",
    "    # (None, 14, 14, 532)\n",
    "    x = layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\", name=\"maxpool_4\")(x)\n",
    "\n",
    "    # (None, 7, 7, 832)\n",
    "    x = Inception(256, 160, 320, 32, 128, 128, name=\"inception_5a\")(x)\n",
    "    # (None, 7, 7, 832)\n",
    "    x = Inception(384, 192, 384, 48, 128, 128, name=\"inception_5b\")(x)\n",
    "    # (None, 7, 7, 1024)\n",
    "    x = layers.AvgPool2D(pool_size=7, strides=1, name=\"avgpool_1\")(x)\n",
    "\n",
    "    # (None, 1, 1, 1024)\n",
    "    x = layers.Flatten(name=\"output_flatten\")(x)\n",
    "    # (None, 1024)\n",
    "    x = layers.Dropout(rate=0.4, name=\"output_dropout\")(x)\n",
    "    x = layers.Dense(class_num, name=\"output_dense\")(x)\n",
    "    # (None, class_num)\n",
    "    aux3 = layers.Softmax(name=\"aux_3\")(x)\n",
    "\n",
    "    if aux_logits:\n",
    "        model = models.Model(inputs=input_image, outputs=[aux1, aux2, aux3])\n",
    "    else:\n",
    "        model = models.Model(inputs=input_image, outputs=aux3)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0dd185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(layers.Layer):\n",
    "    def __init__(self, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        self.branch1 = layers.Conv2D(ch1x1, kernel_size=1, activation=\"relu\")\n",
    "\n",
    "        self.branch2 = Sequential([\n",
    "            layers.Conv2D(ch3x3red, kernel_size=1, activation=\"relu\"),\n",
    "            layers.Conv2D(ch3x3, kernel_size=3, padding=\"SAME\", activation=\"relu\")])      # output_size= input_size\n",
    "\n",
    "        self.branch3 = Sequential([\n",
    "            layers.Conv2D(ch5x5red, kernel_size=1, activation=\"relu\"),\n",
    "            layers.Conv2D(ch5x5, kernel_size=5, padding=\"SAME\", activation=\"relu\")])      # output_size= input_size\n",
    "\n",
    "        self.branch4 = Sequential([\n",
    "            layers.MaxPool2D(pool_size=3, strides=1, padding=\"SAME\"),  # caution: default strides==pool_size\n",
    "            layers.Conv2D(pool_proj, kernel_size=1, activation=\"relu\")])                  # output_size= input_size\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        branch1 = self.branch1(inputs)\n",
    "        branch2 = self.branch2(inputs)\n",
    "        branch3 = self.branch3(inputs)\n",
    "        branch4 = self.branch4(inputs)\n",
    "        outputs = layers.concatenate([branch1, branch2, branch3, branch4])\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c4643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionAux(layers.Layer):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(InceptionAux, self).__init__(**kwargs)\n",
    "        self.averagePool = layers.AvgPool2D(pool_size=5, strides=3)\n",
    "        self.conv = layers.Conv2D(128, kernel_size=1, activation=\"relu\")\n",
    "\n",
    "        self.fc1 = layers.Dense(1024, activation=\"relu\")\n",
    "        self.fc2 = layers.Dense(num_classes)\n",
    "        self.softmax = layers.Softmax()\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14\n",
    "        x = self.averagePool(inputs)\n",
    "        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4\n",
    "        x = self.conv(x)\n",
    "        # N x 128 x 4 x 4\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dropout(rate=0.5)(x)\n",
    "        # N x 2048\n",
    "        x = self.fc1(x)\n",
    "        x = layers.Dropout(rate=0.5)(x)\n",
    "        # N x 1024\n",
    "        x = self.fc2(x)\n",
    "        # N x num_classes\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259dffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # data_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))  # get data root path\n",
    "    # image_path = os.path.join(data_root, \"data_set\", \"flower_data\")  # flower data set path\n",
    "    train_dir = \"C:/桌面/college/大四上/project/flower_dataset/flowers-K-youtube/Train\"\n",
    "    validation_dir = \"C:/桌面/college/大四上/project/flower_dataset/flowers-K-youtube/Validate\"\n",
    "    assert os.path.exists(train_dir), \"cannot find {}\".format(train_dir)\n",
    "    assert os.path.exists(validation_dir), \"cannot find {}\".format(validation_dir)\n",
    "\n",
    "    # create direction for saving weights\n",
    "    if not os.path.exists(\"save_weights\"):\n",
    "        os.makedirs(\"save_weights\")\n",
    "\n",
    "    im_height = 224\n",
    "    im_width = 224\n",
    "    batch_size = 32\n",
    "    epochs = 35\n",
    "\n",
    "    train_accuracy_range = []\n",
    "    val_accuracy_range = []\n",
    "    train_loss_range = []\n",
    "    val_loss_range = []\n",
    "\n",
    "    def pre_function(img):\n",
    "        # img = im.open('test.jpg')\n",
    "        # img = np.array(img).astype(np.float32)\n",
    "        img = img / 255.\n",
    "        img = (img - 0.5) * 2.0\n",
    "\n",
    "        return img\n",
    "\n",
    "    # data generator with data augmentation\n",
    "    train_image_generator = ImageDataGenerator(preprocessing_function=pre_function,\n",
    "                                               horizontal_flip=True)\n",
    "    validation_image_generator = ImageDataGenerator(preprocessing_function=pre_function)\n",
    "\n",
    "    train_data_gen = train_image_generator.flow_from_directory(directory=train_dir,\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               shuffle=True,\n",
    "                                                               target_size=(im_height, im_width),\n",
    "                                                               class_mode='categorical')\n",
    "    total_train = train_data_gen.n\n",
    "\n",
    "    # get class dict\n",
    "    class_indices = train_data_gen.class_indices\n",
    "\n",
    "    # transform value and key of dict\n",
    "    inverse_dict = dict((val, key) for key, val in class_indices.items())\n",
    "    # write dict into json file\n",
    "    json_str = json.dumps(inverse_dict, indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    val_data_gen = validation_image_generator.flow_from_directory(directory=validation_dir,\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  shuffle=False,\n",
    "                                                                  target_size=(im_height, im_width),\n",
    "                                                                  class_mode='categorical')\n",
    "    total_val = val_data_gen.n\n",
    "    print(\"using {} images for training, {} images for validation.\".format(total_train,\n",
    "                                                                           total_val))\n",
    "\n",
    "    model = GoogLeNet(im_height=im_height, im_width=im_width, class_num=5, aux_logits=True)\n",
    "    # model.build((batch_size, 224, 224, 3))  # when using subclass model\n",
    "    model.summary()\n",
    "\n",
    "    # using keras low level api for training\n",
    "    loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "    optimizer =tf.keras.optimizers.RMSprop(lr=0.008, rho=0.9, epsilon=None, decay=0.0)\n",
    "    \n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "    val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "    val_accuracy = tf.keras.metrics.CategoricalAccuracy(name='val_accuracy')\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(images, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            aux1, aux2, output = model(images, training=True)\n",
    "            loss1 = loss_object(labels, aux1)\n",
    "            loss2 = loss_object(labels, aux2)\n",
    "            loss3 = loss_object(labels, output)\n",
    "            loss = loss1 * 0.3 + loss2 * 0.3 + loss3\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        train_loss(loss)\n",
    "        train_accuracy(labels, output)\n",
    "\n",
    "    @tf.function\n",
    "    def val_step(images, labels):\n",
    "        _, _, output = model(images, training=False)\n",
    "        loss = loss_object(labels, output)\n",
    "\n",
    "        val_loss(loss)\n",
    "        val_accuracy(labels, output)\n",
    "\n",
    "\n",
    "    best_val_acc = 0.\n",
    "    for epoch in range(epochs):\n",
    "        train_loss.reset_states()  # clear history info\n",
    "        train_accuracy.reset_states()  # clear history info\n",
    "        val_loss.reset_states()  # clear history info\n",
    "        val_accuracy.reset_states()  # clear history info\n",
    "\n",
    "\n",
    "        # train\n",
    "        train_bar = tqdm(range(total_train // batch_size), file=sys.stdout)\n",
    "\n",
    "        for step in train_bar:\n",
    "            images, labels = next(train_data_gen)\n",
    "            train_step(images, labels)\n",
    "            # print train process\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}, acc:{:.3f}\".format(epoch + 1,\n",
    "                                                                                 epochs,\n",
    "                                                                                 train_loss.result(),\n",
    "                                                                                 train_accuracy.result())\n",
    "        train_accuracy_range.append(train_accuracy.result())\n",
    "        train_loss_range.append(train_loss.result())\n",
    "\n",
    "        # validate\n",
    "        val_bar = tqdm(range(total_val // batch_size), file=sys.stdout)\n",
    "        for step in val_bar:\n",
    "            val_images, val_labels = next(val_data_gen)\n",
    "            val_step(val_images, val_labels)\n",
    "\n",
    "            # print val process\n",
    "            val_bar.desc = \"valid epoch[{}/{}] loss:{:.3f}, acc:{:.3f}\".format(epoch + 1,\n",
    "                                                                               epochs,\n",
    "                                                                               val_loss.result(),\n",
    "                                                                               val_accuracy.result())\n",
    "\n",
    "        val_accuracy_range.append(val_accuracy.result())\n",
    "        val_loss_range.append(val_loss.result())\n",
    "\n",
    "\n",
    "        # only save best weights\n",
    "        if val_accuracy.result() > best_val_acc:\n",
    "            best_val_acc = val_accuracy.result()\n",
    "            \n",
    "            model.save_weights(\"C:/Users/HKY/Desktop/college/googLeNet/save_weights/myGoogLeNet.ckpt28\") \n",
    "            \n",
    "\n",
    "        # plot\n",
    "    epochs_range = range(epochs)  # creating a sequence of number from 0 to number of epochs\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, train_accuracy_range, label=\"Training Accuracy\")\n",
    "    plt.plot(epochs_range, val_accuracy_range, label=\"Validation Accuracy\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, train_loss_range, label=\"Training Loss\")\n",
    "    plt.plot(epochs_range, val_loss_range, label=\"Validation Loss\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and validation Loss')\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c99529f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3278 images belonging to 5 classes.\n",
      "Found 466 images belonging to 5 classes.\n",
      "using 3278 images for training, 466 images for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HKY\\miniconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_1 (MaxPooling2D)        (None, 56, 56, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 64)   4160        maxpool_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 192)  110784      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_2 (MaxPooling2D)        (None, 28, 28, 192)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a (Inception)        (None, 28, 28, 256)  163696      maxpool_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b (Inception)        (None, 28, 28, 480)  388736      inception_3a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_3 (MaxPooling2D)        (None, 14, 14, 480)  0           inception_3b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a (Inception)        (None, 14, 14, 512)  376176      maxpool_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b (Inception)        (None, 14, 14, 512)  449160      inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c (Inception)        (None, 14, 14, 512)  510104      inception_4b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d (Inception)        (None, 14, 14, 528)  605376      inception_4c[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e (Inception)        (None, 14, 14, 832)  868352      inception_4d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_4 (MaxPooling2D)        (None, 7, 7, 832)    0           inception_4e[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a (Inception)        (None, 7, 7, 832)    1043456     maxpool_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b (Inception)        (None, 7, 7, 1024)   1444080     inception_5a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "avgpool_1 (AveragePooling2D)    (None, 1, 1, 1024)   0           inception_5b[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output_flatten (Flatten)        (None, 1024)         0           avgpool_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_dropout (Dropout)        (None, 1024)         0           output_flatten[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output_dense (Dense)            (None, 5)            5125        output_dropout[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "aux_1 (InceptionAux)            (None, 5)            2168965     inception_4a[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aux_2 (InceptionAux)            (None, 5)            2171013     inception_4d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "aux_3 (Softmax)                 (None, 5)            0           output_dense[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,318,655\n",
      "Trainable params: 10,318,655\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "  0%|                                                                                          | 0/102 [01:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " failed to allocate memory\n\t [[node RMSprop/RMSprop/update_118/mul_2 (defined at \\AppData\\Local\\Temp\\ipykernel_11336\\3298015991.py:86) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_step_9156]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node RMSprop/RMSprop/update_118/mul_2:\n gradient_tape/model/aux_1/dense/MatMul_1 (defined at \\AppData\\Local\\Temp\\ipykernel_11336\\3298015991.py:85)\n\nFunction call stack:\ntrain_step\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [5], line 113\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m train_bar:\n\u001b[0;32m    112\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_data_gen)\n\u001b[1;32m--> 113\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# print train process\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     train_bar\u001b[38;5;241m.\u001b[39mdesc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain epoch[\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m] loss:\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m, acc:\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    116\u001b[0m                                                                          epochs,\n\u001b[0;32m    117\u001b[0m                                                                          train_loss\u001b[38;5;241m.\u001b[39mresult(),\n\u001b[0;32m    118\u001b[0m                                                                          train_accuracy\u001b[38;5;241m.\u001b[39mresult())\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  failed to allocate memory\n\t [[node RMSprop/RMSprop/update_118/mul_2 (defined at \\AppData\\Local\\Temp\\ipykernel_11336\\3298015991.py:86) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_step_9156]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node RMSprop/RMSprop/update_118/mul_2:\n gradient_tape/model/aux_1/dense/MatMul_1 (defined at \\AppData\\Local\\Temp\\ipykernel_11336\\3298015991.py:85)\n\nFunction call stack:\ntrain_step\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e861fca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1a13e900340>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_category = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "model = GoogLeNet(class_num=5, aux_logits=False)\n",
    "weights_path = \"C:/Users/HKY/Desktop/college/googLeNet/save_weights/myGoogLeNet.ckpt28\"\n",
    "assert len(glob.glob(weights_path + \"*\")), \"cannot find {}\".format(weights_path)\n",
    "model.load_weights(weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f73342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_flower(test_image):\n",
    "    # resize the test_image\n",
    "    test_image = cv2.resize(test_image, (224, 224))\n",
    "    # convert the image to array\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    # test_image = image_utils.img_to_array(test_image)\n",
    "    # expand the dimensions\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    # predict the image\n",
    "    result = model.predict(test_image)\n",
    "    print(result)\n",
    "    # get the index of the max value\n",
    "    predict_class = np.argmax(result)\n",
    "    # return the flower category\n",
    "\n",
    "    # 该图片为每种花的品种的可能性\n",
    "    # resultAll = np.squeeze(result)\n",
    "    # for i in range(len(resultAll)):\n",
    "    #     print(resultAll[i])\n",
    "\n",
    "    return flower_category[predict_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a5be45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0. 0. 0. 0. 1.]]\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "[[1. 0. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(fn=predict_flower, inputs=\"image\", outputs=\"label\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b2c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
